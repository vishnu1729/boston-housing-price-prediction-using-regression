{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Prices Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates the application of regression to predict the housing prices in Boston. For this the load_boston()\n",
    "is utillized from scikit-learn. \n",
    "The user is free to choose from the following regression algorithms have been used to compare and analyze:\n",
    "    * Decision Tree Regression\n",
    "    * k-Nearest Neighbor Regression\n",
    "    * AdaBoost Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function defitnions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the R^2 score as the performance measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perfMetric(groundTruth,predicted):\n",
    "    perfScore = r2_score(groundTruth,predicted)  # compute the R^2 score as a measure of error\n",
    "    return perfScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Set Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitData(X,y):\n",
    "    Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,y,test_size=0.20,train_size=0.80,random_state=42)\n",
    "    return Xtrain,Ytrain,Xtest,Ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity Curve Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model complexity depict the behavior of the model when the complexity of the model is varied. The training error and test error are recorded as the model parameter is progressivley increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelComplexity(estimatorType,parameter,Xtrain,Ytrain,Xtest, Ytest):\n",
    "    paramRange = np.arange(1,parameter)  # the model complexity parameters are varied from 2 to the specified parameter value\n",
    "    \n",
    "    # Note: pre-allocation as trainError = testError = np.zeros... does not work as the trainError and testError are always \n",
    "    #       held equal by that type of assignment\n",
    "    trainError = np.zeros(len(range(0,len(paramRange)))) # pre-allocate array to record training error\n",
    "    testError = np.zeros(len(range(0,len(paramRange))))  # pre-allocate array to record test error\n",
    "    \n",
    "    for i in range(len(paramRange)):\n",
    "        # generate the appropriate estimator with the parameter in the loop\n",
    "        if estimatorType == 'Decision Tree':\n",
    "            estimator = DecisionTreeRegressor(max_depth = paramRange[i])\n",
    "        elif estimatorType == 'kNN':\n",
    "            estimator = KNeighborsRegressor(n_neighbors = paramRange[i])\n",
    "        else:\n",
    "            estimator = AdaBoostRegressor(n_estimators = paramRange[i])\n",
    "        estimator.fit(Xtrain,Ytrain)\n",
    "        trainError[i] = perfMetric(Ytrain,estimator.predict(Xtrain)) # record training error for the current parameter value\n",
    "        testError[i] = perfMetric(Ytest,estimator.predict(Xtest))    # record test error for the current parameter value\n",
    "    \n",
    "    # plot the model complexity curves i.e the training error and test error\n",
    "    plt.figure()\n",
    "    plt.suptitle('Model complexity curves for %s' % (estimatorType))\n",
    "    plt.plot(paramRange,testError,lw = 2,label = 'Test Error')\n",
    "    plt.plot(paramRange,trainError,lw = 2, label = 'Train Error')\n",
    "    plt.xlabel('Complexity parameter')\n",
    "    plt.ylabel('R2 Score')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning curves depict the behavior of the model with varying training set sizes. The training error and test error are recorded as the training set size is prigressively increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learningCurves(estimatorType,parameter,Xtrain,Ytrain,Xtest,Ytest):\n",
    "    \n",
    "    bestParam = parameter      #the parameter given by the user on examination of the model complexity curves \n",
    "    if estimatorType == 'Decision Tree':\n",
    "        estimator = DecisionTreeRegressor(max_depth = bestParam)\n",
    "        numSamples = np.around(np.linspace(1,Xtrain.shape[0]))\n",
    "    elif estimatorType == 'kNN':\n",
    "        estimator = KNeighborsRegressor(n_neighbors = bestParam)\n",
    "        numSamples = np.around(np.linspace(bestParam,Xtrain.shape[0]))   # the number of training samples is varied from the \n",
    "                                                                         # neightbors since scikit learn requires \n",
    "                                                                         # n_samples >= n_neighbors\n",
    "    else:\n",
    "        estimator = AdaBoostRegressor(n_estimators = bestParam)\n",
    "        numSamples = np.around(np.linspace(1,Xtrain.shape[0]))    \n",
    "    \n",
    "    # numSamples is the array containing number of samples to pass in each iteration\n",
    "    numSamples = numSamples.astype(int)   # numSamples is converted to int to avoid a Deprecation Warning\n",
    "    trainError = np.zeros(len(numSamples)) \n",
    "    testError = np.zeros(len(numSamples))\n",
    "    # the number of training samples is progressivley increased\n",
    "    # the training and test error are recorded in each pass\n",
    "    for i in range(len(numSamples)):\n",
    "        estimator.fit(Xtrain[:numSamples[i]],Ytrain[:numSamples[i]])\n",
    "        trainError[i] = perfMetric(Ytrain[:numSamples[i]],estimator.predict(Xtrain[:numSamples[i]])) \n",
    "        testError[i] = perfMetric(Ytest,estimator.predict(Xtest))\n",
    "    \n",
    "    # plot the learning curves \n",
    "    plt.suptitle('Learning curves for %s at model complexity parameter set to %d' % (estimatorType,bestParam))\n",
    "    plt.plot(numSamples,testError,label = 'Test Error')\n",
    "    plt.plot(numSamples,trainError,label = 'Train Error')\n",
    "    plt.xlabel('Training set size')\n",
    "    plt.ylabel('R2 Score')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the characteristics of the model studied with the above generated curves, a final grid-search with 10-fold cross validation is performed to find the best parameters and the model is fitted for prediction on the unknown test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fitModel(estimatorType,X,y):\n",
    "    folds = KFold(X.shape[0],n_folds = 10,shuffle=True, random_state=40) #KFold object holds attirbutes for grid search\n",
    "    # generate the parameter gris according to the type of the estimator\n",
    "    if estimatorType == 'Decision Tree':\n",
    "        model = DecisionTreeRegressor()\n",
    "        parameters = {\"max_depth\":list(range(1,10))} # depth parameter for decision tree\n",
    "    elif estimatorType == 'kNN':\n",
    "        model = KNeighborsRegressor()\n",
    "        parameters = {\"n_neighbors\":list(range(1,10))} # neighbors parameter for kNN\n",
    "    else:\n",
    "        model = AdaBoostRegressor()\n",
    "        parameters = {\"n_estimators\":list(range(1,10))} # number of base learners for Adaboost\n",
    "    \n",
    "    scoreFun = make_scorer(perfMetric)   # make the defined performance metric into a valid scoring function\n",
    "    paramGrid = GridSearchCV(model,parameters,scoreFun,cv=folds)  # perform grid search\n",
    "    paramGrid = paramGrid.fit(X,y)\n",
    "    return paramGrid.best_estimator_     #return the estimator with the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bostonData = load_boston()\n",
    "priceData = bostonData.data\n",
    "prices = bostonData.target\n",
    "numHouses = prices.shape[0]\n",
    "numFeatures = priceData.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical data properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of houses is 506\n",
      "The number of features for each house is 13\n",
      "The maximum price among houses is $500,000.00\n",
      "The minimum price among houses is $50,000.00\n",
      "The average price among houses is $225,328.06\n",
      "The standard deviation of prices among houses is $91,880.12\n"
     ]
    }
   ],
   "source": [
    "#data analysis\n",
    "print(\"The number of houses is %d\" % numHouses)\n",
    "print(\"The number of features for each house is %d\" % numFeatures)\n",
    "print(\"The maximum price among houses is ${:,.2f}\".format(np.max(prices)*10000))\n",
    "print(\"The minimum price among houses is ${:,.2f}\".format(np.min(prices)*10000))\n",
    "print(\"The average price among houses is ${:,.2f}\".format(np.mean(prices)*10000))\n",
    "print(\"The standard deviation of prices among houses is ${:,.2f}\".format(np.std(prices)*10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate model complexity and learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain,Ytrain,Xtest,Ytest = splitData(priceData,prices)\n",
    "estimatorType = 'AdaBoost'\n",
    "modelComplexity(estimatorType,100,Xtrain,Ytrain,Xtest,Ytest)    # generate model complexity curves\n",
    "learningCurves(estimatorType,10,Xtrain,Ytrain,Xtest,Ytest)      # generate learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and use on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended selling price is $193,801.42\n"
     ]
    }
   ],
   "source": [
    "regressor = fitModel(estimatorType,priceData,prices)         # fit the best estimator\n",
    "toPredict = np.array([11.95, 0.00, 18.100, 0, 0.6590, 5.6090, 90.00, 1.385, 24, 680.0, 20.20, 332.09, 12.13])  # test sample\n",
    "toPredict = toPredict.reshape(1,-1)    # one sample is reshaped from (1,) to (1,n_features) to avoid warning\n",
    "price = regressor.predict(toPredict)   # predict the test sample\n",
    "print(\"Recommended selling price is ${:,.2f}\".format(price[0]*10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'loss': 'linear',\n",
       " 'n_estimators': 6,\n",
       " 'random_state': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.get_params() # estimated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
